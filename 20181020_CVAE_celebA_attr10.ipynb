{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "X0fWovq1E7T_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "import argparse\n",
    "import itertools\n",
    "from os.path import join, exists, splitext, basename\n",
    "from imp import reload\n",
    "from glob import glob\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.nn import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from IPython.display import SVG\n",
    "from IPython.display import display\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import Tars \n",
    "from Tars.distributions import RealNVP, Normal, Bernoulli\n",
    "from Tars.models import ML\n",
    "from Tars.utils import get_dict_values\n",
    "from Tars.distributions.divergences import KullbackLeibler\n",
    "from Tars.models import VAE\n",
    "\n",
    "from utils_tars import *\n",
    "from model_tars_256 import *\n",
    "from imp import reload\n",
    "\n",
    "from solver import Solver\n",
    "from data_loader_sparse import get_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 568,
     "status": "ok",
     "timestamp": 1524787095461,
     "user": {
      "displayName": "Koichiro Mori",
      "photoUrl": "//lh3.googleusercontent.com/-tvNDqPujJp8/AAAAAAAAAAI/AAAAAAAAEFU/jX6gUOYghLg/s50-c-k-no/photo.jpg",
      "userId": "104814186317112306046"
     },
     "user_tz": -540
    },
    "id": "5Vly8sFZZKCm",
    "outputId": "aa10020f-7ee8-49a9-c2fa-030d98d72b9b"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# attr読み込み\n",
    "f = open('./data/list_attr_celeba.txt')\n",
    "lines2 = f.readlines() # 1行毎にファイル終端まで全て読む(改行文字も含まれる)\n",
    "attr = lines2[1]\n",
    "f.close()\n",
    "attr = attr.split(\" \")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(attr)[[2, 4, 15,18, 20, 21,24, 26, 31, 39]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "celebA_loader = get_loader(\"./data/CelebA_nocrop/images\", './data/list_attr_celeba.txt', np.array(attr)[[2, 4, 15,18,20, 21,24, 26,31, 39]])\n",
    "celebA_loader_test = get_loader(\"./data/CelebA_nocrop/images\", './data/list_attr_celeba.txt', np.array(attr)[[2, 4, 15,18,20, 21,24, 26,31, 39]], mode=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(Normal):\n",
    "    def __init__(self, z_dim=63, domain_num=10):\n",
    "        super(Encoder, self).__init__(cond_var=[\"x\", \"y\"], var=[\"z\"])\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        # encode\n",
    "        self.conv_e = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),  # 128 ⇒ 64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # 64 ⇒ 32\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # 32 ⇒ 16\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256 * 16 * 16,  40),\n",
    "        )      \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256 * 16 * 16,  domain_num),\n",
    "        )        \n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(40+domain_num, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 2*self.z_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = self.conv_e(x)\n",
    "        x = x.view(-1, 256 * 16 * 16)\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc2(x)\n",
    "        x = torch.cat([x1, x2*y], dim=1)\n",
    "        x = self.fc(x)\n",
    "        mu = x[:, :self.z_dim]\n",
    "        scale = F.softplus(x[:, self.z_dim:])\n",
    "        return {\"loc\": mu, \"scale\": scale}\n",
    "\n",
    "\n",
    "class Decoder(Bernoulli):\n",
    "    def __init__(self, z_dim=63, domain_num=10):\n",
    "        super(Decoder, self).__init__(cond_var=[\"z\", \"y\"], var=[\"x\"])\n",
    "        \n",
    "        self.z_dim = z_dim \n",
    "\n",
    "        # decode\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(self.z_dim, 40),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(self.z_dim, domain_num),\n",
    "        )\n",
    "        \n",
    "        self.fc_d = nn.Sequential(\n",
    "            nn.Linear(40+domain_num, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 256 * 16 * 16),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.conv_d = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, z, y):\n",
    "        z1 = self.fc1(z)\n",
    "        z2 = self.fc2(z)\n",
    "        z = torch.cat([z1, z2*y], dim=1)\n",
    "        h = self.fc_d(z)\n",
    "        h = h.view(-1, 256, 16, 16)\n",
    "        return {\"probs\": self.conv_d(h)}\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVAE 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder_plot(data_loader, E, D):\n",
    "    E.eval()\n",
    "    D.eval()\n",
    "    \n",
    "    images, labels, _ = iter(data_loader).next()\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    z = E.sample_mean({\"x\": images, \"y\": labels})\n",
    "    samples = D.sample_mean({\"z\": z, \"y\": labels})\n",
    "    samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1).squeeze()\n",
    "    \n",
    "    print(\"↓generate\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(10):\n",
    "        plt.subplot(4, 5, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.subplots_adjust(wspace=0., hspace=0.)\n",
    "        plt.imshow(samples[i])\n",
    "    images = images.cpu().data.numpy().transpose(0, 2, 3, 1).squeeze()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(10):\n",
    "        plt.subplot(4, 5, i+11)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.subplots_adjust(wspace=0., hspace=0.)\n",
    "        plt.imshow(images[i])\n",
    "    plt.savefig(\"./logs/{}.png\".format(epoch+1))\n",
    "    plt.show()\n",
    "    print(\"↑true\")\n",
    "    \n",
    "def manipulate_attribute(data_loader, E, D, domain_num):\n",
    "    scale = 10\n",
    "    E.eval()\n",
    "    D.eval()\n",
    "    images, labels, _ = iter(data_loader).next()\n",
    "    images = images[1:2].to(device)\n",
    "    labels = labels[1:2].to(device)\n",
    "    z = E.sample_mean({\"x\": images, \"y\": labels})\n",
    "    L = labels.repeat(domain_num, 1)\n",
    "    nd = 1 - L.diag()\n",
    "    for k in range(domain_num):\n",
    "        L[k, k] = nd[k] * scale\n",
    "    samples = D.sample_mean({\"z\": z.repeat(domain_num, 1), \"y\": L})\n",
    "    samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1).squeeze()\n",
    "    plt.figure(figsize=(10, int(domain_num/10)))\n",
    "    for i in range(domain_num):\n",
    "        plt.subplot(int(domain_num/10), 10, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.subplots_adjust(wspace=0., hspace=0.)\n",
    "        plt.imshow(samples[i])\n",
    "    plt.savefig(\"./logs/{}.png\".format(epoch+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# E.load_state_dict(torch.load('../ICLR_DVAE_logs/E_{}.pkl'.format(experiment_name)))\n",
    "# D.load_state_dict(torch.load('../ICLR_DVAE_logs/D_{}.pkl'.format(experiment_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    E.train()\n",
    "    D.train()\n",
    "    \n",
    "    train_reconst_loss = 0\n",
    "    train_rate_loss = 0\n",
    "    for batch_idx, (x, y, _) in tqdm(enumerate(celebA_loader)):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # 再構成\n",
    "        E_optimizer.zero_grad()\n",
    "        D_optimizer.zero_grad()\n",
    "\n",
    "        recon_loss = elbo({\"x\": x, \"y\": y}, E, D_)\n",
    "        recon_loss.backward()\n",
    "\n",
    "        E_optimizer.step()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        train_reconst_loss += recon_loss\n",
    "        \n",
    "        if (batch_idx+1) % 10000 == 0:\n",
    "            print(batch_idx+1)\n",
    "            encoder_plot(celebA_loader_test, E, D)\n",
    "            manipulate_attribute(celebA_loader_test, E, D, domain_num)\n",
    "            print(\"Epoch-SCUT: {}, train_recon_loss: {}\".format((epoch + 1), train_reconst_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "domain_num = 10\n",
    "for epoch_ in range(5):\n",
    "    lr = np.random.uniform(1e-4, 1e-3)\n",
    "    z_dim = np.random.randint(50, 300)\n",
    "\n",
    "    log_dir = \"../ICLR_DVAE_logs/\"\n",
    "    experiment_name = 'CVAE_celebA_z{}_lr{:.5f}_attr10'.format(\n",
    "        z_dim, lr)\n",
    "\n",
    "    # prior model p(z)\n",
    "    loc = torch.tensor(0.).to(device)\n",
    "    scale = torch.tensor(1.).to(device)\n",
    "    prior = Normal(loc=loc, scale=scale, var=[\"z\"], dim=z_dim)\n",
    "\n",
    "    E = Encoder(z_dim=z_dim).to(device)\n",
    "    D = Decoder(z_dim=z_dim).to(device)\n",
    "    D_ = D*prior\n",
    "\n",
    "    E_optimizer = optim.Adam(E.parameters(), lr=lr)\n",
    "    D_optimizer = optim.Adam(D.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(3):\n",
    "        train()\n",
    "\n",
    "        torch.save(E.state_dict(), join(log_dir, 'E_{}.pkl'.format(experiment_name)))\n",
    "        torch.save(D.state_dict(), join(log_dir, 'D_{}.pkl'.format(experiment_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "180221-variational-autoencoder.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
