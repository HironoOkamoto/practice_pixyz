{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join, exists\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "\n",
    "from mnist_A_data_loader import get_mnist_A_loader\n",
    "from models import *\n",
    "from utils import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_label = []\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        for k in range(4):\n",
    "            for l in range(10):\n",
    "                unique_label.append([i, j, k, l])\n",
    "unique_label = np.array(unique_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_mnist_A_loader(\"../data/MNIST_A/train_X/\",\n",
    "                                  \"../data/MNIST_A/train_y.npy\", unique_label, onehot=False)\n",
    "test_loader = get_mnist_A_loader(\"../data/MNIST_A/test_X/\",\n",
    "                                 \"../data/MNIST_A/test_y.npy\", unique_label, onehot=False, mode=\"test\")\n",
    "valid_loader = get_mnist_A_loader(\"./data/MNIST_A/valid_X/\",\n",
    "                                  \"../data/MNIST_A/valid_y.npy\", unique_label, onehot=False, mode=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f49eb243a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = iter(test_loader).next()\n",
    "plt.imshow(x[4][0].numpy(), plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MNIST_A_Classifier().to(device)\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "criterion_bce = nn.BCELoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.train()\n",
    "\n",
    "loss_plot = []\n",
    "for epoch in range(3):\n",
    "    for batch_idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y1 = y[:, 0]\n",
    "        y2 = y[:, 1].long()\n",
    "        y3 = y[:, 2].long()\n",
    "        y4 = y[:, 3].long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_y1, pred_y2, pred_y3, pred_y4 = classifier(x)\n",
    "        loss1 = criterion_bce(pred_y1, y1)\n",
    "        loss2 = criterion_ce(pred_y2, y2)\n",
    "        loss3 = criterion_ce(pred_y3, y3)\n",
    "        loss4 = criterion_ce(pred_y4, y4)\n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_plot.append(loss.detach())\n",
    "        \n",
    "        if (batch_idx+1)%1000==0:\n",
    "            plt.plot(loss_plot)\n",
    "            plt.show()\n",
    "\n",
    "log_dir = \"logs\"\n",
    "if not exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "torch.save(classifier.state_dict(), join(log_dir, 'MNIST_A_classifier.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188it [00:09, 20.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size\n",
      "[[11992     8]\n",
      " [    0 12000]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     12000\n",
      "        1.0       1.00      1.00      1.00     12000\n",
      "\n",
      "avg / total       1.00      1.00      1.00     24000\n",
      "\n",
      "0.999666888741\n",
      "\n",
      "rotation\n",
      "[[7899   37   64]\n",
      " [   0 8000    0]\n",
      " [  71   35 7894]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      8000\n",
      "        1.0       0.99      1.00      1.00      8000\n",
      "        2.0       0.99      0.99      0.99      8000\n",
      "\n",
      "avg / total       0.99      0.99      0.99     24000\n",
      "\n",
      "0.991376549771\n",
      "\n",
      "position\n",
      "[[6000    0    0    0]\n",
      " [   0 6000    0    0]\n",
      " [   0    0 6000    0]\n",
      " [   0    0    0 6000]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      6000\n",
      "        1.0       1.00      1.00      1.00      6000\n",
      "        2.0       1.00      1.00      1.00      6000\n",
      "        3.0       1.00      1.00      1.00      6000\n",
      "\n",
      "avg / total       1.00      1.00      1.00     24000\n",
      "\n",
      "1.0\n",
      "\n",
      "label\n",
      "[[2355    1    6    3    1    5   13    1   11    4]\n",
      " [   0 2325   14    8   18    4    1   11   18    1]\n",
      " [   1   13 2296    9   18    1    3   33   26    0]\n",
      " [   3    3   34 2287    3   21    8   14   23    4]\n",
      " [   0    1    8    5 2334    9    4    7    4   28]\n",
      " [   3    3    0   28    7 2304   16    2   26   11]\n",
      " [   3    2    1    6   11   27 2327    0   22    1]\n",
      " [   0    2   52    9   11    8    0 2294   10   14]\n",
      " [   7    6   28   10   12    9    8    4 2297   19]\n",
      " [   5    4    1   29   66   33    6   44   46 2166]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.98      0.99      2400\n",
      "        1.0       0.99      0.97      0.98      2400\n",
      "        2.0       0.94      0.96      0.95      2400\n",
      "        3.0       0.96      0.95      0.95      2400\n",
      "        4.0       0.94      0.97      0.96      2400\n",
      "        5.0       0.95      0.96      0.96      2400\n",
      "        6.0       0.98      0.97      0.97      2400\n",
      "        7.0       0.95      0.96      0.95      2400\n",
      "        8.0       0.93      0.96      0.94      2400\n",
      "        9.0       0.96      0.90      0.93      2400\n",
      "\n",
      "avg / total       0.96      0.96      0.96     24000\n",
      "\n",
      "0.958037861357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"./logs\"\n",
    "classifier = MNIST_A_Classifier().to(device)\n",
    "classifier.load_state_dict(torch.load(join(log_dir, 'MNIST_A_classifier.pkl')))\n",
    "classifier.eval()\n",
    "\n",
    "preds = []\n",
    "ys = []\n",
    "for batch_idx, (data, label) in tqdm(enumerate(test_loader)):\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        pred_y1, pred_y2, pred_y3, pred_y4 = classifier(data)\n",
    "        pred = torch.cat([pred_y1[:, None], pred_y2, pred_y3, pred_y4], 1)\n",
    "        ys.extend(label.numpy())\n",
    "        preds.extend(onehot2label(pred))\n",
    "\n",
    "preds = np.array(preds)\n",
    "ys = np.array(ys)\n",
    "\n",
    "for i, title in enumerate([\"size\", \"rotation\", \"position\", \"label\"]):\n",
    "    print(title)\n",
    "    print(confusion_matrix(ys[:, i], preds[:, i]))\n",
    "    print(classification_report(ys[:, i], preds[:, i]))\n",
    "    print(precision_score(ys[:, i], preds[:, i], average='macro'))\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
