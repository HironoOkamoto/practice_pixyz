{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from pixyz.distributions import DataDistribution\n",
    "from pixyz.models import GAN\n",
    "\n",
    "from models import *\n",
    "from utils import *\n",
    "\n",
    "batch_size = 128\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('../data/mnist', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_test = datasets.MNIST('../data/mnist', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "log_dir = \"./logs/mnist_gif\"\n",
    "if not exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 64\n",
    "\n",
    "# prior model p(z)\n",
    "loc = torch.tensor(0.).to(device)\n",
    "scale = torch.tensor(1.).to(device)\n",
    "prior = Normal(loc=loc, scale=scale, var=[\"z\"], dim=z_dim, name=\"p_prior\")\n",
    "\n",
    "# generative model\n",
    "p_g = generator(input_dim=z_dim)\n",
    "p = (p_g*prior).marginalize_var(\"z\").to(device)\n",
    "\n",
    "# data distribution\n",
    "p_data = DataDistribution([\"x\"]).to(device)\n",
    "\n",
    "d = discriminator().to(device)\n",
    "\n",
    "model = GAN(p_data, p, d,\n",
    "            optimizer=optim.Adam, optimizer_params={\"lr\":0.0002},\n",
    "            d_optimizer=optim.Adam, d_optimizer_params={\"lr\":0.0002})\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 100\n",
    "\n",
    "train_loss = []\n",
    "train_d_loss = []\n",
    "for epoch in range(epoch_num):\n",
    "    for x, _ in tqdm(train_loader):\n",
    "        x = x.to(device)\n",
    "        loss, d_loss = model.train({\"x\": x})\n",
    "        train_loss.append(loss)\n",
    "        train_d_loss.append(d_loss)\n",
    "        \n",
    "    plt.title(\"generator loss\")\n",
    "    plt.plot(train_loss)\n",
    "    plt.title(\"discriminator loss\")\n",
    "    plt.plot(train_d_loss)   \n",
    "    plt.show()\n",
    "    plot_sample(p_g, epoch, z_dim=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "import models\n",
    "import utils\n",
    "reload(utils)\n",
    "reload(models)\n",
    "from models import *\n",
    "from utils import *"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
